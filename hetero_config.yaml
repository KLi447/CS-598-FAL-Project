dispatcher:
  name: "default"
  concurrency_num: 2
datasets:
  - name: "data"
    data: "demo/data.json"
    prompt: "demo/prompt.yaml"
    prompt_type: "instruction"
    preprocess: "shuffle"
adapters:
  - name: "lora_0"
    type: "lora"
    path: "adapters/lora_sft_0"
    optimizer: "adamw"
    lr: 3e-4
    r: 8
    alpha: 64
    dropout: 0.05
    target_modules:
      q_proj: true
      k_proj: true
      v_proj: true
      o_proj: true
      gate_proj: false
      down_proj: false
      up_proj: false
  - name: "lora_1"
    type: "lora"
    path: "adapters/lora_sft_1"
    optimizer: "adamw"
    lr: 3e-5
    r: 128
    alpha: 64
    dropout: 0.05
    target_modules:
      q_proj: true
      k_proj: true
      v_proj: true
      o_proj: true
      gate_proj: false
      down_proj: false
      up_proj: false
  - name: "lora_2"
    type: "lora"
    path: "adapters/lora_sft_2"
    optimizer: "adamw"
    lr: 3e-5
    r: 32
    alpha: 64
    dropout: 0.05
    target_modules:
      q_proj: true
      k_proj: true
      v_proj: true
      o_proj: true
      gate_proj: false
      down_proj: false
      up_proj: false
  - name: "lora_3"
    type: "lora"
    path: "adapters/lora_sft_3"
    optimizer: "adamw"
    lr: 3e-5
    r: 256
    alpha: 64
    dropout: 0.05
    target_modules:
      q_proj: true
      k_proj: true
      v_proj: true
      o_proj: true
      gate_proj: true
      down_proj: true
      up_proj: true
tasks:
  - type: "train"
    name: "task_0"
    adapter: "lora_0"
    dataset: "data"
    batch_size: 64
    mini_batch_size: 64
    num_epochs: 10
    cutoff_len: 256
    save_step: 2000
  - type: "train"
    name: "task_1"
    adapter: "lora_1"
    dataset: "data"
    batch_size: 64
    mini_batch_size: 64
    num_epochs: 10
    cutoff_len: 256
    save_step: 2000
  - type: "train"
    name: "task_2"
    adapter: "lora_2"
    dataset: "data"
    batch_size: 64
    mini_batch_size: 64
    num_epochs: 10
    cutoff_len: 256
    save_step: 2000
  - type: "train"
    name: "task_3"
    adapter: "lora_3"
    dataset: "data"
    batch_size: 64
    mini_batch_size: 64
    num_epochs: 10
    cutoff_len: 256
    save_step: 2000